{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyness Analysis of American vs. Peninsular Spanish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Nicole Dodd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, statsmodels\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "from nltk.corpus import SpanishReader\n",
    "from nltk import FreqDist\n",
    "from collections import defaultdict\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dialectal keyness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load corpora files\n",
    "\n",
    "american_corpus = []\n",
    "peninsular_corpus = []\n",
    "\n",
    "punct = ['-', '--', '\\'', '\\\"', ';', '[', '—', '✚', '§', '#', '´', '<', '>', '+',\n",
    "        '’', '=', ':', '$', ',', '“', '”', '»', '«', '\"', ';', '¿', '?', '¡', '!',\n",
    "        '_', '.', '(', ')', '[', ']', '{', '}', '*', '^', '-', ']', '...']\n",
    "\n",
    "corpora_dir = 'C:/Users/nicol/OneDrive/Documents/Education/Graduate - UCD/2020 Summer/GSR Spanish Corpus/corpora-files/'\n",
    "corpora_files = os.listdir(corpora_dir)\n",
    "\n",
    "for file in corpora_files:\n",
    "    myspreader = SpanishReader.SpanishPlaintextCorpusReader(corpora_dir, file)\n",
    "    text = myspreader.words()\n",
    "    if re.search('a-xix-', file) or re.search('a-xx-', file):\n",
    "        for t in text:\n",
    "            if t not in punct and t.isdigit() == False: # removes punctuation and numbers from analysis\n",
    "                american_corpus.append(t.lower()) # lower case words for freq dist\n",
    "    else: # if peninsular\n",
    "        for t in text:\n",
    "            if t not in punct and t.isdigit() == False: # removes punctuation and numbers from analysis\n",
    "                peninsular_corpus.append(t.lower()) # lower case words for freq dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1614703\n",
      "1419469\n",
      "3034172\n"
     ]
    }
   ],
   "source": [
    "## get corpora sizes\n",
    "\n",
    "am_corp_n = len(american_corpus)\n",
    "print(am_corp_n)\n",
    "pen_corp_n = len(peninsular_corpus)\n",
    "print(pen_corp_n)\n",
    "total_corp = am_corp_n + pen_corp_n\n",
    "print(total_corp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102240\n",
      "83683\n"
     ]
    }
   ],
   "source": [
    "## get unique tokens and type count\n",
    "am_vocab = set(american_corpus)\n",
    "pen_vocab = set(peninsular_corpus)\n",
    "\n",
    "am_corp_type = len(am_vocab)\n",
    "print(am_corp_type)\n",
    "pen_corp_type = len(pen_vocab)\n",
    "print(pen_corp_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get freq distributions\n",
    "\n",
    "am_fd = FreqDist(american_corpus)\n",
    "pen_fd = FreqDist(peninsular_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get common vocabulary\n",
    "\n",
    "span_vocab = list(am_vocab.intersection(pen_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           American  Peninsular\n",
      "don            2344        1902\n",
      "pedro           465         284\n",
      "de            91615       81677\n",
      "lara              5           5\n",
      "doña            866         795\n",
      "...             ...         ...\n",
      "coloco            1           2\n",
      "apuraré           1           1\n",
      "intercede         1           1\n",
      "recetas           1           1\n",
      "epidemias         1           1\n",
      "\n",
      "[45816 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "## build table of freq distributions of common vocabulary\n",
    "\n",
    "corpora_freq = defaultdict(list) # initialize dict with list for values\n",
    "\n",
    "# initialize with freqs from American corpus\n",
    "for (key, value) in am_fd.items(): \n",
    "    if key in span_vocab:\n",
    "            corpora_freq[key].append(value)\n",
    "\n",
    "# add freqs from Peninsular corpus\n",
    "for (key, value) in pen_fd.items():\n",
    "    if key in span_vocab:\n",
    "            corpora_freq[key].append(value)\n",
    "\n",
    "# convert to dataframe\n",
    "corpora_freq_df = pd.DataFrame.from_dict(corpora_freq, orient = 'index', columns = ['American', 'Peninsular'])\n",
    "print(corpora_freq_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats\n",
    "**chi-squared statistic:** Determines whether there is a statistically significant difference between the *expected* frequencies and *observed* frequencies in one or more categories of a contingency table. A measure of independence.<br><br>\n",
    "**log likelihood ratio:** Determines whether the distribution of A given B is the same as the distribution if A without B. If the words A and B occur independently, then we would expect *p(AB)* = *p(A)p(B)*. A measure of independence.<br><br>\n",
    "**odds ratio:** Determines the strength of association or non-independence between data values. A measure of correlation.<br><br>\n",
    "**Kullback-Leibler (KL) divergence:** Quantifies the difference between two probability distributions. Less conflated with frequency than LLR (Gries forthcoming).<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### American dialectal keyness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run suite of keyness tests\n",
    "\n",
    "# initialize dicts to gather data\n",
    "am_pearson_chi = {}\n",
    "am_log_likelihood = {}\n",
    "am_odds_ratio = {}\n",
    "\n",
    "for word in span_vocab:\n",
    "    \n",
    "    # build contingency table\n",
    "    am_cont_table = [[am_fd[word], am_corp_n - am_fd[word]], [pen_fd[word], pen_corp_n - pen_fd[word]]]\n",
    "    am_cont_table_stats = sm.stats.Table(am_cont_table)\n",
    "    \n",
    "    # get Pearson chi-squared statistic\n",
    "    chi = am_cont_table_stats.test_nominal_association()\n",
    "    am_pearson_chi[word] = [chi.statistic, chi.pvalue]\n",
    "    \n",
    "    # compare to same measure with scipy (note: same values as with statsmodels as long as correction = False)\n",
    "    am_sp_chi = sp.stats.chi2_contingency(am_cont_table, correction = False)\n",
    "    \n",
    "    # get log likelihood ratio\n",
    "    log = sp.stats.chi2_contingency(am_cont_table, correction = False, lambda_ = 'log-likelihood')\n",
    "    am_log_likelihood[word] = [log[0], log[1], log[2]]\n",
    "    \n",
    "    # get odds ratio\n",
    "    odds = am_cont_table_stats.local_log_oddsratios\n",
    "    am_odds_ratio[word] = odds[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert dicts to dfs\n",
    "\n",
    "am_pearson_chi_df = pd.DataFrame.from_dict(am_pearson_chi, orient = 'index', columns = ['chi-statistic', 'pvalue'])\n",
    "am_log_likelihood_df = pd.DataFrame.from_dict(am_log_likelihood, orient = 'index', columns = ['chi-statistic', \n",
    "                                                                                        'pvalue', \n",
    "                                                                                        'deg-of-freedom'])\n",
    "am_odds_ratio_df = pd.DataFrame.from_dict(am_odds_ratio, orient = 'index', columns = ['odds'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pearson chi-statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              chi-statistic    pvalue\n",
      "irregulares        0.871869  0.350438\n",
      "asesina            0.278217  0.597873\n",
      "estragado          1.279240  0.258040\n",
      "evite              3.219605  0.072761\n",
      "precio            10.360744  0.001287\n",
      "...                     ...       ...\n",
      "padrino            3.923273  0.047622\n",
      "convenciones       2.185802  0.139288\n",
      "mandobles          0.350845  0.553635\n",
      "dés                0.008315  0.927344\n",
      "letras             5.264201  0.021768\n",
      "\n",
      "[45816 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(am_pearson_chi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           chi-statistic    pvalue\n",
      "alicia        101.360102  0.000000\n",
      "cap.           89.466362  0.000000\n",
      "apolonio      197.445153  0.000000\n",
      "inés          108.541734  0.000000\n",
      "barcelona      71.062309  0.000000\n",
      "...                  ...       ...\n",
      "ofendido        3.857771  0.049516\n",
      "presto          3.857771  0.049516\n",
      "estarán         3.857771  0.049516\n",
      "santuario       3.857771  0.049516\n",
      "eres            3.855227  0.049591\n",
      "\n",
      "[6052 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "## filter for significant results\n",
    "\n",
    "am_pearson_chi_sig = am_pearson_chi_df[am_pearson_chi_df['pvalue'] <= 0.05]\n",
    "print(am_pearson_chi_sig.sort_values('pvalue'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "## export to Excel\n",
    "\n",
    "am_pearson_chi_sig.to_excel('am-pearson-chi-sig.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              chi-statistic    pvalue  deg-of-freedom\n",
      "irregulares        0.893510  0.344528               1\n",
      "asesina            0.277550  0.598312               1\n",
      "estragado          1.320830  0.250443               1\n",
      "evite              3.451404  0.063198               1\n",
      "precio            10.356034  0.001291               1\n",
      "...                     ...       ...             ...\n",
      "padrino            4.077198  0.043466               1\n",
      "convenciones       2.420457  0.119760               1\n",
      "mandobles          0.350968  0.553566               1\n",
      "dés                0.008298  0.927419               1\n",
      "letras             5.330527  0.020955               1\n",
      "\n",
      "[45816 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(am_log_likelihood_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           chi-statistic         pvalue  deg-of-freedom\n",
      "á            2431.760738   0.000000e+00               1\n",
      "i            2389.914930   0.000000e+00               1\n",
      "do           1199.566146  7.578579e-263               1\n",
      "y             947.343192  5.014976e-208               1\n",
      "nieves        699.911134  3.126286e-154               1\n",
      "...                  ...            ...             ...\n",
      "furiosos        3.848933   4.977764e-02               1\n",
      "cantares        3.848933   4.977764e-02               1\n",
      "insensato       3.848933   4.977764e-02               1\n",
      "cuadro          3.846686   4.984440e-02               1\n",
      "eres            3.845578   4.987733e-02               1\n",
      "\n",
      "[6484 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "## filter for significant results\n",
    "\n",
    "am_log_likelihood_sig = am_log_likelihood_df[am_log_likelihood_df['pvalue'] <= 0.05]\n",
    "print(am_log_likelihood_sig.sort_values('pvalue'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## export to Excel\n",
    "\n",
    "am_log_likelihood_sig.to_excel('am-log-likelihood-sig.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Odds ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  odds\n",
      "irregulares   0.564281\n",
      "asesina      -0.352013\n",
      "estragado    -1.227482\n",
      "evite        -1.738309\n",
      "precio       -0.495521\n",
      "...                ...\n",
      "padrino       0.764957\n",
      "convenciones  1.480572\n",
      "mandobles    -0.534334\n",
      "dés          -0.128868\n",
      "letras        0.352125\n",
      "\n",
      "[45816 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(am_odds_ratio_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                odds\n",
      "teatros     0.000344\n",
      "volvían     0.000344\n",
      "tiró        0.000344\n",
      "importaba   0.000344\n",
      "cubiertas   0.000344\n",
      "...              ...\n",
      "bruno       4.719405\n",
      "leonardo    4.937081\n",
      "villaverde  4.952635\n",
      "baldomero   5.287371\n",
      "méxico      5.326597\n",
      "\n",
      "[18589 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "## filter for positive log odds\n",
    "\n",
    "am_odds_ratio_pos = am_odds_ratio_df[am_odds_ratio_df['odds'] >= 0]\n",
    "print(am_odds_ratio_pos.sort_values('odds'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "## export to Excel\n",
    "\n",
    "am_odds_ratio_pos.to_excel('am-odds-ratio-pos.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peninsular dialectal keyness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run suite of keyness tests\n",
    "\n",
    "# initialize dicts to gather data\n",
    "pen_pearson_chi = {}\n",
    "pen_log_likelihood = {}\n",
    "pen_odds_ratio = {}\n",
    "\n",
    "for word in span_vocab:\n",
    "    \n",
    "    # build contingency table\n",
    "    pen_cont_table = [[pen_fd[word], pen_corp_n - pen_fd[word]], [am_fd[word], am_corp_n - am_fd[word]]]\n",
    "    pen_cont_table_stats = sm.stats.Table(pen_cont_table)\n",
    "    \n",
    "    # get Pearson chi-squared statistic\n",
    "    chi = pen_cont_table_stats.test_nominal_association()\n",
    "    pen_pearson_chi[word] = [chi.statistic, chi.pvalue]\n",
    "    \n",
    "    # compare to same measure with scipy (note: same values as with statsmodels as long as correction = False)\n",
    "    pen_sp_chi = sp.stats.chi2_contingency(pen_cont_table, correction = False)\n",
    "    \n",
    "    # get log likelihood ratio\n",
    "    log = sp.stats.chi2_contingency(pen_cont_table, correction = False, lambda_ = 'log-likelihood')\n",
    "    pen_log_likelihood[word] = [log[0], log[1], log[2]]\n",
    "    \n",
    "    # get odds ratio\n",
    "    odds = pen_cont_table_stats.local_log_oddsratios\n",
    "    pen_odds_ratio[word] = odds[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert dicts to dfs\n",
    "\n",
    "pen_pearson_chi_df = pd.DataFrame.from_dict(pen_pearson_chi, orient = 'index', columns = ['chi-statistic', 'pvalue'])\n",
    "pen_log_likelihood_df = pd.DataFrame.from_dict(pen_log_likelihood, orient = 'index', columns = ['chi-statistic', \n",
    "                                                                                        'pvalue', \n",
    "                                                                                        'deg-of-freedom'])\n",
    "pen_odds_ratio_df = pd.DataFrame.from_dict(pen_odds_ratio, orient = 'index', columns = ['odds'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pearson chi-statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              chi-statistic    pvalue\n",
      "irregulares        0.871869  0.350438\n",
      "asesina            0.278217  0.597873\n",
      "estragado          1.279240  0.258040\n",
      "evite              3.219605  0.072761\n",
      "precio            10.360744  0.001287\n",
      "...                     ...       ...\n",
      "padrino            3.923273  0.047622\n",
      "convenciones       2.185802  0.139288\n",
      "mandobles          0.350845  0.553635\n",
      "dés                0.008315  0.927344\n",
      "letras             5.264201  0.021768\n",
      "\n",
      "[45816 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pen_pearson_chi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           chi-statistic    pvalue\n",
      "alicia        101.360102  0.000000\n",
      "cap.           89.466362  0.000000\n",
      "apolonio      197.445153  0.000000\n",
      "inés          108.541734  0.000000\n",
      "barcelona      71.062309  0.000000\n",
      "...                  ...       ...\n",
      "ofendido        3.857771  0.049516\n",
      "presto          3.857771  0.049516\n",
      "estarán         3.857771  0.049516\n",
      "santuario       3.857771  0.049516\n",
      "eres            3.855227  0.049591\n",
      "\n",
      "[6052 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "## filter for significant results\n",
    "\n",
    "pen_pearson_chi_sig = pen_pearson_chi_df[pen_pearson_chi_df['pvalue'] <= 0.05]\n",
    "print(pen_pearson_chi_sig.sort_values('pvalue'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "## export to Excel\n",
    "\n",
    "pen_pearson_chi_sig.to_excel('pen-pearson-chi-sig.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              chi-statistic    pvalue  deg-of-freedom\n",
      "irregulares        0.893510  0.344528               1\n",
      "asesina            0.277550  0.598312               1\n",
      "estragado          1.320830  0.250443               1\n",
      "evite              3.451404  0.063198               1\n",
      "precio            10.356034  0.001291               1\n",
      "...                     ...       ...             ...\n",
      "padrino            4.077198  0.043466               1\n",
      "convenciones       2.420457  0.119760               1\n",
      "mandobles          0.350968  0.553566               1\n",
      "dés                0.008298  0.927419               1\n",
      "letras             5.330527  0.020955               1\n",
      "\n",
      "[45816 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pen_log_likelihood_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           chi-statistic         pvalue  deg-of-freedom\n",
      "á            2431.760738   0.000000e+00               1\n",
      "i            2389.914930   0.000000e+00               1\n",
      "do           1199.566146  7.578579e-263               1\n",
      "y             947.343192  5.014976e-208               1\n",
      "nieves        699.911134  3.126286e-154               1\n",
      "...                  ...            ...             ...\n",
      "furiosos        3.848933   4.977764e-02               1\n",
      "cantares        3.848933   4.977764e-02               1\n",
      "insensato       3.848933   4.977764e-02               1\n",
      "cuadro          3.846686   4.984440e-02               1\n",
      "eres            3.845578   4.987733e-02               1\n",
      "\n",
      "[6484 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "## filter for significant results\n",
    "\n",
    "pen_log_likelihood_sig = pen_log_likelihood_df[pen_log_likelihood_df['pvalue'] <= 0.05]\n",
    "print(pen_log_likelihood_sig.sort_values('pvalue'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "## export to Excel\n",
    "\n",
    "pen_log_likelihood_sig.to_excel('pen-log-likelihood-sig.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Odds ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  odds\n",
      "irregulares  -0.564281\n",
      "asesina       0.352013\n",
      "estragado     1.227482\n",
      "evite         1.738309\n",
      "precio        0.495521\n",
      "...                ...\n",
      "padrino      -0.764957\n",
      "convenciones -1.480572\n",
      "mandobles     0.534334\n",
      "dés           0.128868\n",
      "letras       -0.352125\n",
      "\n",
      "[45816 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pen_odds_ratio_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              odds\n",
      "dignidad  0.000035\n",
      "ardiente  0.000035\n",
      "suerte    0.000327\n",
      "grito     0.000390\n",
      "dió       0.000487\n",
      "...            ...\n",
      "batiste   5.354745\n",
      "azorín    5.499657\n",
      "gray      5.763854\n",
      "leto      6.110561\n",
      "regina    6.197598\n",
      "\n",
      "[27227 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "## filter for positive log odds\n",
    "\n",
    "pen_odds_ratio_pos = pen_odds_ratio_df[pen_odds_ratio_df['odds'] >= 0]\n",
    "print(pen_odds_ratio_pos.sort_values('odds'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "## export to Excel\n",
    "\n",
    "pen_odds_ratio_pos.to_excel('pen-odds-ratio-pos.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KL divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_contingency(span_vocab):\n",
    "    \n",
    "    output = {}\n",
    "    \n",
    "    for word in span_vocab:\n",
    "    \n",
    "        word_freq = am_fd[word] + pen_fd[word]\n",
    "        total_corpora = am_corp_n + pen_corp_n\n",
    "        \n",
    "        # probability of am corpus given word\n",
    "        p_am_word = am_fd[word] / word_freq\n",
    "        # probability of pen corpus given word\n",
    "        p_pen_word = pen_fd[word] / word_freq\n",
    "        # probability of target corpus (am) given corpora\n",
    "        p_t_corpora = am_corp_n / total_corpora\n",
    "        # probability of reference corpus given corpora\n",
    "        p_r_corpora = pen_corp_n / total_corpora\n",
    "\n",
    "        kl_cont_table = [[(am_fd[word] / word_freq), # probability of am corpus given word\n",
    "                          (pen_fd[word] / word_freq)], # probability of pen corpus given word\n",
    "                         [(am_corp_n / total_corpora), # probability of target corpus given corpora\n",
    "                          (pen_corp_n / total_corpora)]] # probability of reference corpus given corpora\n",
    "        \n",
    "        kl = (p_am_word * log((p_am_word / p_t_corpora), 2)) + (p_pen_word * log((p_pen_word / p_r_corpora), 2))\n",
    "        \n",
    "        output[word] = kl\n",
    "        \n",
    "    return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get KL divergence\n",
    "\n",
    "kl_divergence = kl_contingency(span_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              kl-divergence\n",
      "irregulares        0.053711\n",
      "asesina            0.022245\n",
      "estragado          0.238194\n",
      "evite              0.414943\n",
      "precio             0.043683\n",
      "...                     ...\n",
      "padrino            0.094873\n",
      "convenciones       0.290998\n",
      "mandobles          0.050634\n",
      "dés                0.002993\n",
      "letras             0.021601\n",
      "\n",
      "[45816 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "## convert dict to df\n",
    "\n",
    "kl_divergence_df = pd.DataFrame.from_dict(kl_divergence, orient = 'index', columns = ['kl-divergence'])\n",
    "print(kl_divergence_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           kl-divergence\n",
      "regina      1.071967e+00\n",
      "leto        1.070108e+00\n",
      "gray        1.061217e+00\n",
      "azorín      1.052525e+00\n",
      "batiste     1.046905e+00\n",
      "...                  ...\n",
      "tiró        2.119619e-08\n",
      "importaba   2.119619e-08\n",
      "suerte      1.921486e-08\n",
      "ardiente    2.238996e-10\n",
      "dignidad    2.238996e-10\n",
      "\n",
      "[45816 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "## print sorted\n",
    "\n",
    "print(kl_divergence_df.sort_values('kl-divergence', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "## export to Excel\n",
    "\n",
    "kl_divergence_df.to_excel('kl-divergence.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps:\n",
    "Incorporate text dispersion as a measure of frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
